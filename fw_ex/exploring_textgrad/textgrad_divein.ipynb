{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4697ba82-40ff-4920-bbaf-00167f47582a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textgrad import (\n",
    "    set_backward_engine,\n",
    "    BlackboxLLM,\n",
    "    Variable,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1595519-2324-4e1e-93e7-d975d3775f62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv(\"/media/uberdev/ddrv/gitFolders/python_de_learners_data/.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5cdd277-dfe0-4b0b-a5d8-217618da5972",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_backward_engine(engine=\"gpt-4o-mini\", override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "16dbdad6-2aa4-4571-842d-f334724b1bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BlackboxLLM(engine=\"gpt-4o-mini\")\n",
    "\n",
    "question = (\"If it takes 1hr to dry 25 shirts under the sun,\"\n",
    "            \"How long will it take to dry 30 shirts under sun? reason step by step\")\n",
    "# the parenthesis is the way to break the sentences, \n",
    "# not a tuple\n",
    "diamond_question = (\"I put a diamond in a cup and then placed the cup upside down on my bed,\"\n",
    "                    \"Later I came back, took the cup, and put it in the fridge. Where is the diamond?\")\n",
    "\n",
    "question_var = Variable(value=diamond_question,\n",
    "                        role_description=\"Question to LLM\",\n",
    "                        requires_grad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d0c45cff-1aa5-4d7d-a893-a8a1cf61ecd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I put a diamond in a cup and then placed the cup upside down on my bed,Later I came back, took the cup, and put it in the fridge. Where is the diamond?Make correct assumptions'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diamond_question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bdc8a907-da8e-4f94-97b5-559dfa22d836",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable(value=The diamond is still in the cup. When you placed the cup upside down on your bed, the diamond would have remained inside the cup. When you later took the cup and put it in the fridge, the diamond went with it. So, the diamond is now in the cup, which is in the fridge., role=response from the language model, grads=set())"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer = model(question_var)\n",
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b4a6bd60-1191-4003-9a57-26e3880a1be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textgrad import TGD\n",
    "\n",
    "answer.set_role_description(\"concise and accurate answer to the question\")\n",
    "\n",
    "# defining the loss function, Text Grad Descent\n",
    "optimizer = TGD(parameters=[answer],engine='gpt-4o')\n",
    "valuation_instrn = (f\"Here's a question: {diamond_question}.\"\n",
    "                    \"Evaluate any given answer to ths question\"\n",
    "                    \"Be smart, logical and very critical\"\n",
    "                    \"Just provide concise feedback\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "450fa01c-a2d2-4461-b999-81a30fee0bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textgrad import TextLoss\n",
    "\n",
    "loss_fn = TextLoss(eval_system_prompt=valuation_instrn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0769d88b-b79e-43b2-9974-ad56b7d92f74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable(value=The answer is correct. The diamond remained inside the cup throughout the described actions. When the cup was placed upside down, the diamond did not fall out, and when the cup was moved to the fridge, the diamond was taken along with it. Thus, the diamond is indeed in the cup, which is now in the fridge. The reasoning is logical and follows the sequence of events accurately., role=response from the language model, grads=set())"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = loss_fn(answer)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "548bbb03-49e8-4300-b2e6-3892fb86661d",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7802cdb6-385b-44bb-8401-2deb0fd23138",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "64119eb9-0b14-4d61-acc6-8fa8e59a9419",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable(value=The diamond is in the fridge. When you placed the cup upside down on your bed, the diamond remained inside. Later, when you moved the cup to the fridge, the diamond went with it., role=concise and accurate answer to the question, grads={Variable(value=To improve the concise and accurate answer, consider the following feedback:\n",
       "\n",
       "1. **Conciseness**: The response could be more succinct. While the explanation is accurate, it could be streamlined by removing redundant phrases. For example, the phrase \"the diamond is still in the cup\" could be shortened to \"the diamond remains in the cup,\" which conveys the same meaning with fewer words.\n",
       "\n",
       "2. **Clarity**: While the reasoning is logical, the structure could be enhanced for clarity. Presenting the sequence of events in a more straightforward manner could help. For instance, stating the final location of the diamond first (\"The diamond is in the fridge\") followed by a brief explanation of how it got there could improve the flow.\n",
       "\n",
       "3. **Avoiding Repetition**: The phrase \"in the cup\" is repeated unnecessarily. Instead of reiterating that the diamond is in the cup and then again stating it is in the cup in the fridge, you could consolidate this information to avoid redundancy.\n",
       "\n",
       "4. **Directness**: The answer could benefit from a more direct approach. Starting with the conclusion and then providing the reasoning can make the answer feel more decisive. For example, leading with \"The diamond is in the fridge\" followed by a brief explanation of how it got there would enhance the impact.\n",
       "\n",
       "5. **Logical Emphasis**: While the reasoning is sound, emphasizing the key logical point—that the cup was upside down and the diamond did not fall out—could strengthen the argument. A brief mention of the cup's position could reinforce why the diamond remained inside.\n",
       "\n",
       "By implementing these strategies, the answer can become more concise, clear, and impactful, ultimately improving the objective function of providing a concise and accurate response., role=feedback to concise and accurate answer to the question, grads=set())})"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0ab2b9-8659-41e9-8166-19ee7e74bdf1",
   "metadata": {},
   "source": [
    "Diving into the primitives of TextGrad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f883f8cc-e55b-4b66-9ae0-f35b5ea7a90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable is the main data structure\n",
    "x = Variable(\"A sentnke with typo\",\n",
    "             role_description=\"The input sentence\",\n",
    "             requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c1241af2-5abc-46c4-be8d-c3a97081a7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# engine is the LLM\n",
    "from textgrad import get_engine\n",
    "engine = get_engine(\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "152ffe26-f720-4b34-91ff-11edde6841e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm just a computer program, so I don't have feelings, but I'm here and ready to help you! How can I assist you today?\""
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engine.generate(\"How are you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8ddcfc9e-8d53-420a-a502-fcfac7e4c018",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys_prompt = Variable(\"Evaluate the sentence correctness\",\n",
    "                      role_description=\"System Prompt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "95f74d44-e867-4a1c-b146-5b75874ccb5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = TextLoss(sys_prompt, engine=engine,)\n",
    "\n",
    "# How the loss is calculate with respect to a string?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c08a6406-7439-45cd-a807-d698d36322d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = loss(x)\n",
    "# when sending through the loss, the sentence is corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "be3edbfa-242d-4a17-be34-8293ad875f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "l.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "802b8cff-38ed-4fad-96a8-1fcb7629fa0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textgrad import TextualGradientDescent\n",
    "\n",
    "optimizer = TextualGradientDescent(parameters=[x],\n",
    "                                   engine=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6e7eea90-8f80-4b91-b2bc-fda82a7d6086",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "aab42d25-fb03-428b-9246-03044f73d223",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This sentence contains a typo.'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "84cea59b-a639-44ed-b2ba-86ae60a68818",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.zero_grad()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
