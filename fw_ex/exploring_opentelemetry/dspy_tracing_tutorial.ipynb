{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8JmV5eAaLQ2D"
   },
   "source": [
    "!pip install \"regex~=2023.10.3\" dspy-ai  # DSPy requires an old version of regex that conflicts with the installed version on Colab\n",
    "!pip install arize-phoenix openinference-instrumentation-dspy opentelemetry-exporter-otlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "id": "9tM6ZiQcLQ2G",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/uberdev/ddrv/telemetenv/lib/python3.10/site-packages/pydantic/_internal/_config.py:341: UserWarning: Valid config keys have changed in V2:\n",
      "* 'allow_population_by_field_name' has been renamed to 'populate_by_name'\n",
      "* 'smart_union' has been removed\n",
      "  warnings.warn(message, UserWarning)\n",
      "/media/uberdev/ddrv/telemetenv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import dspy\n",
    "import openai\n",
    "import phoenix as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(\"/media/uberdev/ddrv/gitFolders/python_de_learners_data/.env\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XLdPJ7l5LQ2H"
   },
   "source": [
    "## 2. Configure Your OpenAI API Key\n",
    "\n",
    "Set your OpenAI API key if it is not already set as an environment variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lTS1KUcMLQ2J"
   },
   "source": [
    "## 3. Configure Module Components\n",
    "\n",
    "A module consists of components such as a language model (in this case, OpenAI's GPT 3.5 turbo), akin to the layers of a PyTorch module and a retriever (in this case, ColBERTv2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "5Bj2y_pHLQ2K"
   },
   "outputs": [],
   "source": [
    "turbo = dspy.OpenAI(model=\"gpt-4o-mini\")\n",
    "colbertv2_wiki17_abstracts = dspy.ColBERTv2(\n",
    "    url=\"http://20.102.90.50:2017/wiki17_abstracts\"  # endpoint for a hosted ColBERTv2 service\n",
    ")\n",
    "\n",
    "dspy.settings.configure(lm=turbo,\n",
    "                        rm=colbertv2_wiki17_abstracts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dcE9cbgMLQ2K"
   },
   "source": [
    "## 4. Load Data\n",
    "\n",
    "Load a subset of the HotpotQA dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Yk-Uhd28LQ2L"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading builder script: 100%|██████████| 6.42k/6.42k [00:00<00:00, 13.2kB/s]\n",
      "Downloading readme: 100%|██████████| 9.19k/9.19k [00:00<00:00, 16.4kB/s]\n",
      "Downloading data: 100%|██████████| 566M/566M [01:26<00:00, 6.53MB/s]   \n",
      "Downloading data: 100%|██████████| 47.5M/47.5M [00:09<00:00, 4.84MB/s]\n",
      "Downloading data: 100%|██████████| 46.2M/46.2M [00:08<00:00, 5.70MB/s]\n",
      "Generating train split: 100%|██████████| 90447/90447 [00:56<00:00, 1594.74 examples/s]\n",
      "Generating validation split: 100%|██████████| 7405/7405 [00:04<00:00, 1720.33 examples/s]\n",
      "Generating test split: 100%|██████████| 7405/7405 [00:03<00:00, 2039.87 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 20\n",
      "Dev set size: 50\n"
     ]
    }
   ],
   "source": [
    "from dspy.datasets import HotPotQA\n",
    "\n",
    "# Load the dataset.\n",
    "dataset = HotPotQA(train_seed=1, train_size=20, eval_seed=2023, dev_size=50, test_size=10)\n",
    "\n",
    "# Tell DSPy that the 'question' field is the input. Any other fields are labels and/or metadata.\n",
    "trainset = [x.with_inputs(\"question\") for x in dataset.train]\n",
    "devset = [x.with_inputs(\"question\") for x in dataset.dev]\n",
    "\n",
    "print(f\"Train set size: {len(trainset)}\")\n",
    "print(f\"Dev set size: {len(devset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DH7co6h3LQ2L"
   },
   "source": [
    "Each example in our training set has a question and a human-annotated answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "FYbtoPu5LQ2M"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Example({'question': 'At My Window was released by which American singer-songwriter?', 'answer': 'John Townes Van Zandt'}) (input_keys={'question'})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_example = trainset[0]\n",
    "train_example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "55iFL1FILQ2M"
   },
   "source": [
    "Examples in the dev set have a third field containing titles of relevant Wikipedia articles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "PcRGbz0FLQ2M"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Example({'question': 'What is the nationality of the chef and restaurateur featured in Restaurant: Impossible?', 'answer': 'English', 'gold_titles': {'Restaurant: Impossible', 'Robert Irvine'}}) (input_keys={'question'})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_example = devset[18]\n",
    "dev_example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VTAmEuEKLQ2N"
   },
   "source": [
    "## 5. Define Your RAG Module\n",
    "\n",
    "Define a signature that takes in two inputs, `context` and `question`, and outputs an `answer`. The signature provides:\n",
    "\n",
    "- A description of the sub-task the language model is supposed to solve.\n",
    "- A description of the input fields to the language model.\n",
    "- A description of the output fields the language model must produce."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "DeC5JPY8LQ2N"
   },
   "outputs": [],
   "source": [
    "class GenerateAnswer(dspy.Signature):\n",
    "    \"\"\"Answer questions with short factoid answers.\"\"\"\n",
    "\n",
    "    context = dspy.InputField(desc=\"may contain relevant facts\")\n",
    "    question = dspy.InputField()\n",
    "    answer = dspy.OutputField(desc=\"often between 1 and 5 words\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Td0jbe2oLQ2N"
   },
   "source": [
    "Define your module by subclassing `dspy.Module` and overriding the `forward` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "zirCKzq6LQ2O"
   },
   "outputs": [],
   "source": [
    "class RAG(dspy.Module):\n",
    "    def __init__(self, num_passages=3):\n",
    "        super().__init__()\n",
    "        self.retrieve = dspy.Retrieve(k=num_passages)\n",
    "        self.generate_answer = dspy.ChainOfThought(GenerateAnswer)\n",
    "\n",
    "    def forward(self, question):\n",
    "        context = self.retrieve(question).passages\n",
    "        prediction = self.generate_answer(context=context, question=question)\n",
    "        return dspy.Prediction(context=context, answer=prediction.answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yy0BXijELQ2O"
   },
   "source": [
    "This module uses retrieval-augmented generation (using the previously configured ColBERTv2 retriever) in tandem with chain of thought in order to generate the final answer to the user."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bH4exsH6LQ2O"
   },
   "source": [
    "## 6. Compile Your RAG Module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JgKS0gcTLQ2P"
   },
   "source": [
    "In this case, we'll use the default `BootstrapFewShot` teleprompter that selects good demonstrations from the the training dataset for inclusion in the final prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wykTQYIcLQ2P",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 7. Instrument DSPy and Launch Phoenix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "id": "B1LTXliPLQ2Q",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:phoenix.config:📋 Ensuring phoenix working directory: /home/uberdev/.phoenix\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🌍 To view the Phoenix app in your browser, visit http://localhost:6006/\n",
      "📖 For more information on how to use Phoenix, check out https://docs.arize.com/phoenix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR [strawberry.execution] Cannot convert value to AST: {}.\n",
      "\n",
      "GraphQL request:61:7\n",
      "60 |       type { ...TypeRef }\n",
      "61 |       defaultValue\n",
      "   |       ^\n",
      "62 |       isDeprecated\n",
      "Traceback (most recent call last):\n",
      "  File \"/media/uberdev/ddrv/telemetenv/lib/python3.10/site-packages/graphql/execution/execute.py\", line 521, in execute_field\n",
      "    result = resolve_fn(source, info, **args)\n",
      "  File \"/media/uberdev/ddrv/telemetenv/lib/python3.10/site-packages/graphql/type/introspection.py\", line 485, in default_value\n",
      "    value_ast = ast_from_value(item[1].default_value, item[1].type)\n",
      "  File \"/media/uberdev/ddrv/telemetenv/lib/python3.10/site-packages/graphql/utilities/ast_from_value.py\", line 63, in ast_from_value\n",
      "    ast_value = ast_from_value(value, type_.of_type)\n",
      "  File \"/media/uberdev/ddrv/telemetenv/lib/python3.10/site-packages/graphql/utilities/ast_from_value.py\", line 136, in ast_from_value\n",
      "    raise TypeError(f\"Cannot convert value to AST: {inspect(serialized)}.\")\n",
      "TypeError: Cannot convert value to AST: {}.\n",
      "ERROR [strawberry.execution] Cannot convert value to AST: {}.\n",
      "\n",
      "GraphQL request:61:7\n",
      "60 |       type { ...TypeRef }\n",
      "61 |       defaultValue\n",
      "   |       ^\n",
      "62 |       isDeprecated\n",
      "Traceback (most recent call last):\n",
      "  File \"/media/uberdev/ddrv/telemetenv/lib/python3.10/site-packages/graphql/execution/execute.py\", line 521, in execute_field\n",
      "    result = resolve_fn(source, info, **args)\n",
      "  File \"/media/uberdev/ddrv/telemetenv/lib/python3.10/site-packages/graphql/type/introspection.py\", line 485, in default_value\n",
      "    value_ast = ast_from_value(item[1].default_value, item[1].type)\n",
      "  File \"/media/uberdev/ddrv/telemetenv/lib/python3.10/site-packages/graphql/utilities/ast_from_value.py\", line 63, in ast_from_value\n",
      "    ast_value = ast_from_value(value, type_.of_type)\n",
      "  File \"/media/uberdev/ddrv/telemetenv/lib/python3.10/site-packages/graphql/utilities/ast_from_value.py\", line 136, in ast_from_value\n",
      "    raise TypeError(f\"Cannot convert value to AST: {inspect(serialized)}.\")\n",
      "TypeError: Cannot convert value to AST: {}.\n"
     ]
    }
   ],
   "source": [
    "# getting phoenix server\n",
    "# This need not be run, as the server is running locally on your machine\n",
    "phoenix_session = px.launch_app()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1723809344.767450   22964 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution -rotobuf (/media/uberdev/ddrv/telemetenv/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -rotobuf (/media/uberdev/ddrv/telemetenv/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting openinference-instrumentation-dspy\n",
      "  Using cached openinference_instrumentation_dspy-0.1.11-py3-none-any.whl (13 kB)\n",
      "Requirement already satisfied: typing-extensions in /media/uberdev/ddrv/telemetenv/lib/python3.10/site-packages (from openinference-instrumentation-dspy) (4.12.2)\n",
      "Requirement already satisfied: wrapt in /media/uberdev/ddrv/telemetenv/lib/python3.10/site-packages (from openinference-instrumentation-dspy) (1.16.0)\n",
      "Requirement already satisfied: openinference-semantic-conventions in /media/uberdev/ddrv/telemetenv/lib/python3.10/site-packages (from openinference-instrumentation-dspy) (0.1.9)\n",
      "Requirement already satisfied: opentelemetry-api in /media/uberdev/ddrv/telemetenv/lib/python3.10/site-packages (from openinference-instrumentation-dspy) (1.26.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation in /media/uberdev/ddrv/telemetenv/lib/python3.10/site-packages (from openinference-instrumentation-dspy) (0.47b0)\n",
      "Requirement already satisfied: openinference-instrumentation>=0.1.12 in /media/uberdev/ddrv/telemetenv/lib/python3.10/site-packages (from openinference-instrumentation-dspy) (0.1.14)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions in /media/uberdev/ddrv/telemetenv/lib/python3.10/site-packages (from openinference-instrumentation-dspy) (0.47b0)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in /media/uberdev/ddrv/telemetenv/lib/python3.10/site-packages (from opentelemetry-api->openinference-instrumentation-dspy) (1.2.14)\n",
      "Requirement already satisfied: importlib-metadata<=8.0.0,>=6.0 in /media/uberdev/ddrv/telemetenv/lib/python3.10/site-packages (from opentelemetry-api->openinference-instrumentation-dspy) (8.0.0)\n",
      "Requirement already satisfied: setuptools>=16.0 in /media/uberdev/ddrv/telemetenv/lib/python3.10/site-packages (from opentelemetry-instrumentation->openinference-instrumentation-dspy) (59.6.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /media/uberdev/ddrv/telemetenv/lib/python3.10/site-packages (from importlib-metadata<=8.0.0,>=6.0->opentelemetry-api->openinference-instrumentation-dspy) (3.20.0)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -rotobuf (/media/uberdev/ddrv/telemetenv/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: openinference-instrumentation-dspy\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -rotobuf (/media/uberdev/ddrv/telemetenv/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mSuccessfully installed openinference-instrumentation-dspy-0.1.11\n"
     ]
    }
   ],
   "source": [
    "# Other libraries are installed when phoenix-arize is installed\n",
    "!pip install openinference-instrumentation-dspy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv(\"/media/uberdev/ddrv/gitFolders/python_de_learners_data/.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openinference.instrumentation.dspy import DSPyInstrumentor\n",
    "# instruments the internal calls in DSPy library\n",
    "from opentelemetry import trace as trace_api\n",
    "from opentelemetry.exporter.otlp.proto.http.trace_exporter import OTLPSpanExporter\n",
    "# help to get the span of http requests to the APIs\n",
    "from opentelemetry.sdk import trace as trace_sdk\n",
    "#processes the data collected from the spans\n",
    "from opentelemetry.sdk.resources import Resource\n",
    "from openinference.semconv.resource import ResourceAttributes\n",
    "from opentelemetry.sdk.trace.export import SimpleSpanProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dspy.teleprompt import BootstrapFewShot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation logic: check that the predicted answer is correct.\n",
    "# Also check that the retrieved context does actually contain that answer.\n",
    "def validate_context_and_answer(example, pred, trace=None):\n",
    "    # Need to check what can be given in the place of None for the trace\n",
    "    answer_EM = dspy.evaluate.answer_exact_match(example,\n",
    "                                                 pred)\n",
    "    answer_PM = dspy.evaluate.answer_passage_match(example,\n",
    "                                                   pred)\n",
    "    return answer_EM and answer_PM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_module = RAG()\n",
    "teleprompter = BootstrapFewShot(metric=validate_context_and_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "lj9b9TsNLQ2R"
   },
   "outputs": [],
   "source": [
    "endpoint = \"http://127.0.0.1:6006/v1/traces\"\n",
    "resource = Resource(attributes={})\n",
    "\n",
    "tracer_provider = trace_sdk.TracerProvider(resource=resource)\n",
    "span_otlp_exporter = OTLPSpanExporter(endpoint=endpoint)\n",
    "\n",
    "tracer_provider.add_span_processor(SimpleSpanProcessor(span_exporter=span_otlp_exporter))\n",
    "\n",
    "trace_api.set_tracer_provider(tracer_provider=tracer_provider)\n",
    "\n",
    "DSPyInstrumentor().instrument(skip_dep_check=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "DwUJmrahLQ2P"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 11/20 [00:22<00:18,  2.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 4 full traces after 12 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "compiled_module = teleprompter.compile(input_module,\n",
    "                                       trainset=trainset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bus66hKGLQ2Q"
   },
   "source": [
    "Then instrument your application with [OpenInference](https://github.com/Arize-ai/openinference/tree/main/spec), an open standard build atop [OpenTelemetry](https://opentelemetry.io/) that captures and stores LLM application executions. OpenInference provides telemetry data to help you understand the invocation of your LLMs and the surrounding application context, including retrieval from vector stores, the usage of external tools or APIs, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rrSfrsb5LQ2R"
   },
   "source": [
    "## 8. Run Your Application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QEuj4WAJLQ2R"
   },
   "source": [
    "Let's run our DSPy application on the dev set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mWkQVXouLQ2S"
   },
   "outputs": [],
   "source": [
    "for example in devset:\n",
    "    question = example[\"question\"]\n",
    "    prediction = compiled_module(question)\n",
    "    print(\"Question\")\n",
    "    print(\"========\")\n",
    "    print(question)\n",
    "    print()\n",
    "    print(\"Predicted Answer\")\n",
    "    print(\"================\")\n",
    "    print(prediction.answer)\n",
    "    print()\n",
    "    print(\"Retrieved Contexts (truncated)\")\n",
    "    print(f\"{[c[:200] + '...' for c in prediction.context]}\")\n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Ia5OJHGLQ2S"
   },
   "source": [
    "Check the Phoenix UI to inspect the architecture of your DSPy module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tu2r4di2LQ2T"
   },
   "outputs": [],
   "source": [
    "print(phoenix_session.url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HzD13MBmLQ2T"
   },
   "source": [
    "A few things to note:\n",
    "\n",
    "- The spans in each trace correspond to the steps in the `forward` method of our custom subclass of `dspy.Module`,\n",
    "- The call to `ColBERTv2` appears as a retriever span with retrieved documents and scores displayed for each forward pass,\n",
    "- The LLM span includes the fully-formatted prompt containing few-shot examples computed by DSPy during compilation.\n",
    "\n",
    "![a tour of your traces and spans in DSPy, highlighting retriever and LLM spans in particular](https://storage.googleapis.com/arize-phoenix-assets/assets/docs/notebooks/dspy-tracing-tutorial/dspy_spans_and_traces.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sfq7EYU9LQ2U"
   },
   "source": [
    "Congrats! You've used DSPy to bootstrap a multishot prompt with hard negative passages and chain of thought, and you've used Phoenix to observe the inner workings of DSPy and understand the internals of the forward pass."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
